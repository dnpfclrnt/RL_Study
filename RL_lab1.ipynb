{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.0474103 , 0.00768469, 0.03536078, 0.00068417], dtype=float32), {})\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "env = gym.make('CartPole-v1', render_mode=\"rgb_array\")\n",
    "observation = env.reset()\n",
    "\n",
    "print(observation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0.0474103 , 0.00768469, 0.03536078, 0.00068417], dtype=float32), {})\n",
      "[ 0.0462951   0.14573042 -0.00352884 -0.29547256]\n",
      "[ 0.04920971 -0.04934104 -0.00943829 -0.00390467]\n",
      "[ 0.04822289 -0.24432637 -0.00951638  0.2857855 ]\n",
      "[ 0.04333636 -0.43931133 -0.00380067  0.5754519 ]\n",
      "[ 0.03455014 -0.24413629  0.00770837  0.28157407]\n",
      "[ 0.02966741 -0.43936735  0.01333985  0.57667816]\n",
      "[ 0.02088006 -0.2444349   0.02487341  0.28822732]\n",
      "[ 0.01599137 -0.43990254  0.03063796  0.58865017]\n",
      "[ 0.00719331 -0.24522273  0.04241096  0.30577362]\n",
      "[ 0.00228886 -0.05073     0.04852644  0.02676194]\n",
      "[ 0.00127426  0.14366366  0.04906167 -0.25022414]\n",
      "[ 0.00414753 -0.05212333  0.04405719  0.05752131]\n",
      "[ 0.00310507 -0.24784838  0.04520762  0.36377263]\n",
      "[-0.0018519  -0.05339712  0.05248307  0.08568025]\n",
      "[-0.00291984 -0.24923056  0.05419667  0.39444888]\n",
      "[-0.00790446 -0.445078    0.06208565  0.70371467]\n",
      "[-0.01680601 -0.6410029   0.07615995  1.0152773 ]\n",
      "[-0.02962607 -0.8370533   0.09646549  1.3308698 ]\n",
      "[-0.04636714 -0.6432713   0.12308289  1.0698651 ]\n",
      "[-0.05923256 -0.4499729   0.14448018  0.8182061 ]\n",
      "[-0.06823202 -0.2570928   0.16084431  0.57422996]\n",
      "[-0.07337388 -0.06454784  0.1723289   0.33622503]\n",
      "[-0.07466484 -0.2616496   0.17905341  0.67791283]\n",
      "[-0.07989783 -0.06940734  0.19261166  0.44652042]\n",
      "[-0.08128598  0.12254267  0.20154208  0.22019815]\n",
      "[-0.07883512 -0.07480394  0.20594604  0.5690794 ]\n",
      "Episode finished after 27 time steps\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "observation = state\n",
    "reward = reward\n",
    "done = whether it's time to reset environment\n",
    "\"\"\"\n",
    "\n",
    "env.reset()\n",
    "for k in range(100):\n",
    "    env.render()\n",
    "    print(observation)\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, done, _, info = env.step(action)\n",
    "    if done:\n",
    "        print(\"Episode finished after {} time steps\".format(k + 1))\n",
    "        break\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_bins_pos = 10\n",
    "n_bins_vel = 10\n",
    "n_bins_ang = 10\n",
    "n_bins_anv = 10\n",
    "\n",
    "def map_discrete_state(state):\n",
    "    pos, vel, ang, anv = state\n",
    "\n",
    "    idx_pos = np.where(np.histogram(np.clip(pos, -2, 2), bins= n_bins_pos, range=(-2, 2))[0] == 1)[0][0]\n",
    "    idx_vel = np.where(np.histogram(np.clip(vel, -2, 2), bins= n_bins_vel, range=(-2, 2))[0] == 1)[0][0]\n",
    "    idx_ang = np.where(np.histogram(np.clip(ang, -0.4, 0.4), bins= n_bins_ang, range=(-0.4, 0.4))[0] == 1)[0][0]\n",
    "    idx_anv = np.where(np.histogram(np.clip(anv, -2, 2), bins= n_bins_anv, range=(-2, 2))[0] == 1)[0][0]\n",
    "\n",
    "    states = np.zeros([n_bins_pos, n_bins_vel, n_bins_ang, n_bins_anv])\n",
    "    states[idx_pos, idx_vel, idx_ang, idx_ang] = 1\n",
    "\n",
    "    states = states.reshape(-1, 1)\n",
    "    s = np.where(states == 1)[0][0]\n",
    "\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_states = n_bins_pos * n_bins_vel * n_bins_ang * n_bins_anv\n",
    "n_actions = 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/private/tmp/PKInstallSandbox.oNjx7s/tmp/ipykernel_62979/2226680874.py:27: RuntimeWarning: overflow encountered in scalar add\n",
      "  Q_table[s, a] = (1 - alpha) * Q_table[s, a] + alpha * reward + gamma * np.max(Q_table[next_s, :])\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.3\n",
    "gamma = 0.9\n",
    "\n",
    "Q_table = np.random.uniform(0, 1, (n_states, n_actions))\n",
    "\n",
    "for episode in range(801):\n",
    "    done = False\n",
    "    state = env.reset()\n",
    "    state = tuple(state[0])\n",
    "\n",
    "    while not done:\n",
    "        s = map_discrete_state(state)\n",
    "\n",
    "        epsilon = 0.1\n",
    "        if np.random.uniform() < epsilon:\n",
    "            a = env.action_space.sample()\n",
    "        else:\n",
    "            a = np.argmax(Q_table[s, :])\n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(a)\n",
    "\n",
    "        if done: \n",
    "            reward = -100\n",
    "            Q_table[s, a] = reward\n",
    "        else:\n",
    "            next_s = map_discrete_state(next_state)\n",
    "            Q_table[s, a] = (1 - alpha) * Q_table[s, a] + alpha * reward + gamma * np.max(Q_table[next_s, :])\n",
    "        state = next_state\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.35606817, 0.55556244],\n",
       "       [0.26443476, 0.54034142],\n",
       "       [0.87293781, 0.32369064],\n",
       "       ...,\n",
       "       [0.01518989, 0.84195374],\n",
       "       [0.4994129 , 0.10684662],\n",
       "       [0.96481926, 0.89767094]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "state = tuple(state[0])\n",
    "done = False\n",
    "while not done:\n",
    "    env.render()\n",
    "    s = map_discrete_state(state)\n",
    "    action = np.argmax(Q_table[s, :])\n",
    "    next_state, _, done, _, _ = env.step(action)\n",
    "    state = next_state\n",
    "\n",
    "env.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
